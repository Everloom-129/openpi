"""
Visualization of FAST (Frequency-space Action Sequence Tokenization)
Based on the paper: https://arxiv.org/pdf/2501.09747

FAST uses DCT (Discrete Cosine Transform) compression to tokenize robot actions,
similar to JPEG compression for images.
"""

import matplotlib.pyplot as plt
import matplotlib.patches as mpatches
from matplotlib.patches import FancyBboxPatch, Rectangle
import numpy as np
from scipy.fftpack import dct, idct

# Create figure with multiple subplots
fig = plt.figure(figsize=(20, 14), facecolor="white")

# ============================================================================
# 1. Problem: Naive Binning vs FAST
# ============================================================================
ax1 = plt.subplot(4, 2, (1, 2))
ax1.set_title(
    "Problem: Naive Per-Timestep Binning Fails for High-Frequency Control", fontsize=16, weight="bold", pad=15
)
ax1.set_xlim(0, 10)
ax1.set_ylim(0, 3)
ax1.axis("off")

# Naive binning example
y_pos = 2.2
ax1.text(0.5, y_pos + 0.3, "Naive Binning (e.g., OpenVLA):", fontsize=12, weight="bold", color="darkred")

# Show correlated action sequence
actions_naive = [0.5, 0.52, 0.51, 0.53, 0.52, 0.54, 0.53, 0.55]
tokens_naive = ["bin_128", "bin_133", "bin_130", "bin_135", "bin_133", "bin_138", "bin_135", "bin_140"]

for i, (action, token) in enumerate(zip(actions_naive, tokens_naive)):
    x = i * 1.2
    # Action value
    ax1.text(
        x,
        y_pos,
        f"{action:.2f}",
        ha="center",
        fontsize=10,
        bbox=dict(boxstyle="round", facecolor="lightcoral", alpha=0.7),
    )
    # Arrow
    ax1.annotate(
        "", xy=(x, y_pos - 0.2), xytext=(x, y_pos - 0.05), arrowprops=dict(arrowstyle="->", lw=1.5, color="black")
    )
    # Token
    ax1.text(x, y_pos - 0.4, token, ha="center", fontsize=8, bbox=dict(boxstyle="round", facecolor="pink", alpha=0.8))

ax1.text(
    5,
    y_pos - 0.7,
    "âŒ Highly correlated tokens â†’ Poor for autoregressive prediction",
    ha="center",
    fontsize=11,
    style="italic",
    color="darkred",
)

# FAST approach
y_pos = 0.8
ax1.text(0.5, y_pos + 0.3, "FAST (Frequency-space Tokenization):", fontsize=12, weight="bold", color="darkgreen")

# Show DCT compressed sequence
ax1.text(1, y_pos, "Actions", ha="center", fontsize=10, bbox=dict(boxstyle="round", facecolor="lightblue", alpha=0.7))
ax1.annotate("", xy=(2, y_pos), xytext=(1.5, y_pos), arrowprops=dict(arrowstyle="->", lw=2, color="black"))
ax1.text(
    2.5, y_pos, "DCT\nCompress", ha="center", fontsize=10, bbox=dict(boxstyle="round", facecolor="yellow", alpha=0.7)
)
ax1.annotate("", xy=(3.5, y_pos), xytext=(3, y_pos), arrowprops=dict(arrowstyle="->", lw=2, color="black"))
ax1.text(
    4.5,
    y_pos,
    "Frequency\nCoefficients",
    ha="center",
    fontsize=10,
    bbox=dict(boxstyle="round", facecolor="lightgreen", alpha=0.7),
)
ax1.annotate("", xy=(5.5, y_pos), xytext=(5, y_pos), arrowprops=dict(arrowstyle="->", lw=2, color="black"))
ax1.text(
    6.5, y_pos, "FSQ\nQuantize", ha="center", fontsize=10, bbox=dict(boxstyle="round", facecolor="orange", alpha=0.7)
)
ax1.annotate("", xy=(7.5, y_pos), xytext=(7, y_pos), arrowprops=dict(arrowstyle="->", lw=2, color="black"))
ax1.text(8.5, y_pos, "Tokens", ha="center", fontsize=10, bbox=dict(boxstyle="round", facecolor="lightcoral", alpha=0.7))

ax1.text(
    5,
    y_pos - 0.5,
    "âœ… Decorrelated tokens â†’ Better for autoregressive prediction",
    ha="center",
    fontsize=11,
    style="italic",
    color="darkgreen",
)

# ============================================================================
# 2. DCT Transform Visualization
# ============================================================================
ax2 = plt.subplot(4, 2, 3)
ax2.set_title("Step 1: DCT Transform (Time â†’ Frequency)", fontsize=14, weight="bold")

# Generate example action trajectory
t = np.linspace(0, 2 * np.pi, 50)
action_trajectory = 0.5 * np.sin(t) + 0.3 * np.sin(3 * t) + 0.2 * np.sin(5 * t)

ax2.plot(t, action_trajectory, "b-", linewidth=2, label="Action trajectory")
ax2.set_xlabel("Time", fontsize=11)
ax2.set_ylabel("Action value", fontsize=11)
ax2.grid(True, alpha=0.3)
ax2.legend()
ax2.set_facecolor("lightyellow")

ax3 = plt.subplot(4, 2, 4)
ax3.set_title("DCT Coefficients (Frequency Domain)", fontsize=14, weight="bold")

# Apply DCT
dct_coeffs = dct(action_trajectory, norm="ortho")
ax3.stem(dct_coeffs[:20], basefmt=" ", linefmt="g-", markerfmt="go")
ax3.set_xlabel("Frequency index", fontsize=11)
ax3.set_ylabel("Coefficient magnitude", fontsize=11)
ax3.grid(True, alpha=0.3)
ax3.axhline(y=0, color="k", linestyle="-", linewidth=0.5)
ax3.set_facecolor("lightgreen")
ax3.text(
    10,
    max(dct_coeffs[:20]) * 0.8,
    "Low frequencies\n(smooth motion)",
    fontsize=10,
    bbox=dict(boxstyle="round", facecolor="yellow", alpha=0.7),
)

# ============================================================================
# 3. FSQ Quantization
# ============================================================================
ax4 = plt.subplot(4, 2, 5)
ax4.set_title("Step 2: FSQ Quantization", fontsize=14, weight="bold")
ax4.axis("off")
ax4.set_xlim(0, 1)
ax4.set_ylim(0, 1)

fsq_text = """
FSQ (Finite Scalar Quantization):
â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”

1. Project DCT coefficients to lower dimension
   z = tanh(Linear(dct_coeffs))
   
2. Quantize to discrete bins
   For codebook size 2^8:
   â€¢ bins_per_dim = (8, 6, 5)
   â€¢ Total codes = 8 Ã— 6 Ã— 5 = 240 â‰ˆ 2^8
   
3. Convert to single token ID
   token_id = dâ‚€ + dâ‚Ã—8 + dâ‚‚Ã—8Ã—6
   
Example:
  DCT coeffs: [2.3, -1.5, 0.8, ...]
       â†“
  Quantized: [3, 2, 1]  (digits in each dimension)
       â†“
  Token ID: 3 + 2Ã—8 + 1Ã—48 = 67
"""

ax4.text(
    0.05,
    0.95,
    fsq_text,
    fontsize=10,
    va="top",
    ha="left",
    family="monospace",
    bbox=dict(boxstyle="round", facecolor="lightcyan", alpha=0.9),
)

# ============================================================================
# 4. Token Sequence Structure
# ============================================================================
ax5 = plt.subplot(4, 2, 6)
ax5.set_title("Step 3: Token Sequence in PaliGemma", fontsize=14, weight="bold")
ax5.set_xlim(0, 10)
ax5.set_ylim(0, 2)
ax5.axis("off")

tokens = [
    ("Image\nTokens", "lightblue", 1.2),
    ("BOS", "yellow", 0.4),
    ("Prefix\n(Task+State)", "lightgreen", 1.5),
    ("\\n", "orange", 0.3),
    ("Action:", "pink", 0.6),
    ("FAST\nTokens", "lightcoral", 1.2),
    ("|", "orange", 0.2),
    ("EOS", "yellow", 0.4),
]

y_pos = 1.0
x_offset = 0.2
for i, (text, color, width) in enumerate(tokens):
    x_start = x_offset

    box = FancyBboxPatch(
        (x_start, y_pos - 0.25),
        width,
        0.5,
        boxstyle="round,pad=0.03",
        facecolor=color,
        edgecolor="black",
        linewidth=1.5,
    )
    ax5.add_patch(box)

    ax5.text(x_start + width / 2, y_pos, text, ha="center", va="center", fontsize=9, weight="bold")

    x_offset += width + 0.1

    if i < len(tokens) - 1:
        ax5.annotate(
            "",
            xy=(x_offset - 0.05, y_pos),
            xytext=(x_offset - 0.1, y_pos),
            arrowprops=dict(arrowstyle="->", lw=1.5, color="black"),
        )

ax5.text(
    5,
    0.3,
    "FAST tokens are mapped to last 128 tokens in PaliGemma vocab",
    ha="center",
    fontsize=10,
    style="italic",
    color="darkblue",
)

# ============================================================================
# 5. Complete Pipeline
# ============================================================================
ax6 = plt.subplot(4, 2, (7, 8))
ax6.set_title("Complete FAST Pipeline", fontsize=16, weight="bold", pad=15)
ax6.axis("off")
ax6.set_xlim(0, 1)
ax6.set_ylim(0, 1)

pipeline_text = """
â•”â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•—
â•‘                            FAST Tokenization Pipeline                                     â•‘
â•šâ•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

ENCODING (Actions â†’ Tokens):
â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”

Input: Action trajectory [T Ã— D]
  T = action horizon (e.g., 15 timesteps)
  D = action dimension (e.g., 8 for joint velocities + gripper)

Step 1: DCT Transform
  â”œâ”€ Apply 1D DCT along time dimension for each action dimension
  â”œâ”€ Compresses temporal correlations into frequency components
  â””â”€ Output: DCT coefficients [T Ã— D]

Step 2: FSQ Quantization
  â”œâ”€ Project to lower dimension: z = tanh(Linear(dct_coeffs))
  â”œâ”€ Quantize each dimension to discrete bins
  â”œâ”€ Convert multi-dimensional bins to single token ID
  â””â”€ Output: Token sequence [N tokens]
     â€¢ N depends on compression ratio (e.g., 15Ã—8 actions â†’ 8 tokens)

Step 3: Map to PaliGemma Vocab
  â”œâ”€ FAST tokens use last 128 slots in PaliGemma vocab (257024-257151)
  â”œâ”€ token_pg = vocab_size - 1 - 128 - token_fast
  â””â”€ Insert into sequence: "Action: <token_1> <token_2> ... <token_N> |"

DECODING (Tokens â†’ Actions):
â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”

Step 1: Extract FAST tokens from generated sequence
  â””â”€ Parse: "Action: <tokens> |" â†’ extract token IDs

Step 2: Inverse FSQ Quantization
  â”œâ”€ Convert token ID back to multi-dimensional bins
  â”œâ”€ Dequantize: z = (bins / (bases-1)) Ã— 2 - 1
  â””â”€ Project up: dct_coeffs = Linear(z)

Step 3: Inverse DCT Transform
  â”œâ”€ Apply IDCT along time dimension
  â””â”€ Output: Reconstructed actions [T Ã— D]

KEY ADVANTAGES:
â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”

âœ“ Compression: 15Ã—8 = 120 values â†’ 8 tokens (15x reduction)
âœ“ Decorrelation: DCT removes temporal correlation between tokens
âœ“ Universal: FAST+ trained on 1M trajectories works across robots
âœ“ Efficiency: 5x faster training than diffusion VLAs
âœ“ Performance: Matches diffusion VLA performance on dexterous tasks

CODE REFERENCE (from src/openpi/models/tokenizer.py):
â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”

class FASTTokenizer:
    def tokenize(self, prompt, state, actions):
        # Encode text prefix
        prefix = f"Task: {prompt}, State: {state_str};\\n"
        prefix_tokens = paligemma_tokenizer.encode(prefix, add_bos=True)
        
        # Encode actions with FAST
        action_tokens = fast_tokenizer(actions)  # DCT + FSQ
        action_tokens_pg = self._map_to_paligemma_vocab(action_tokens)
        
        # Construct postfix
        postfix = encode("Action: ") + action_tokens_pg + encode("|", add_eos=True)
        
        return prefix_tokens + postfix_tokens
"""

ax6.text(
    0.02,
    0.98,
    pipeline_text,
    fontsize=9,
    va="top",
    ha="left",
    family="monospace",
    bbox=dict(boxstyle="round", facecolor="lavender", alpha=0.95),
)

plt.tight_layout()
plt.savefig("results/fast_tokenizer_explanation.png", dpi=150, bbox_inches="tight")
print("âœ… Saved FAST tokenizer explanation to: results/fast_tokenizer_explanation.png")
plt.close()

# ============================================================================
# Create second figure: Comparison with other tokenization methods
# ============================================================================
fig2 = plt.figure(figsize=(18, 10), facecolor="white")

ax = fig2.add_subplot(111)
ax.axis("off")
ax.set_xlim(0, 1)
ax.set_ylim(0, 1)
ax.set_title("Tokenization Methods Comparison", fontsize=18, weight="bold", pad=20)

comparison_text = """
â•”â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•—
â•‘                     Robot Action Tokenization Methods Comparison                          â•‘
â•šâ•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

1. NAIVE BINNING (RT-2, OpenVLA)
â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”
Method: Per-dimension, per-timestep binning
  â€¢ Discretize each action dimension into N bins (e.g., 256)
  â€¢ Each timestep gets D tokens (one per dimension)
  â€¢ For 15 timesteps Ã— 8 dims = 120 tokens

Pros:
  âœ“ Simple to implement
  âœ“ No learned components

Cons:
  âœ— Highly correlated consecutive tokens
  âœ— Fails for high-frequency control (>10Hz)
  âœ— Large number of tokens for action chunks
  âœ— Poor for dexterous manipulation

Example: action = [0.52, -0.31, 0.15, ...]
         â†’ tokens = [bin_133, bin_89, bin_165, ...]


2. FAST (Frequency-space Action Sequence Tokenization)
â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”
Method: DCT compression + FSQ quantization
  â€¢ Apply DCT to compress temporal dimension
  â€¢ Use FSQ to quantize frequency coefficients
  â€¢ 15Ã—8 actions â†’ 8 tokens (15x compression)

Pros:
  âœ“ Decorrelates consecutive tokens
  âœ“ Works for high-frequency control (20-60Hz)
  âœ“ Efficient compression (15x reduction)
  âœ“ Universal tokenizer (FAST+) works across robots
  âœ“ 5x faster training than diffusion

Cons:
  âœ— Requires learned FSQ quantizer
  âœ— Slight reconstruction error

Example: actions [15Ã—8] â†’ DCT â†’ FSQ â†’ [8 tokens]


3. DIFFUSION (Ï€â‚€ baseline)
â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”
Method: Continuous diffusion process
  â€¢ No tokenization - predict continuous actions directly
  â€¢ Use denoising diffusion to generate action sequences

Pros:
  âœ“ No discretization error
  âœ“ Works well for dexterous tasks
  âœ“ Handles multimodal action distributions

Cons:
  âœ— 5x slower training than FAST
  âœ— Slower inference (requires multiple denoising steps)
  âœ— Cannot leverage pre-trained language models directly


PERFORMANCE COMPARISON (from paper):
â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”

Task                  â”‚ Naive Binning â”‚  FAST   â”‚ Diffusion
â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
Table Bussing         â”‚     ~0%       â”‚  83%    â”‚   85%
T-Shirt Folding       â”‚     ~0%       â”‚  60%    â”‚   60%
Laundry Folding       â”‚     ~0%       â”‚  40%    â”‚   40%
DROID (16 tasks)      â”‚     N/A       â”‚  61%    â”‚   N/A

Training Time         â”‚     1x        â”‚   1x    â”‚   5x
Inference Speed       â”‚    Fast       â”‚  Fast   â”‚  Slow


WHEN TO USE EACH METHOD:
â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”

Naive Binning:
  â€¢ Low-frequency tasks (<5Hz)
  â€¢ Simple pick-and-place
  â€¢ When training speed is not critical

FAST:
  â€¢ High-frequency control (20-60Hz)
  â€¢ Dexterous manipulation
  â€¢ When training efficiency matters
  â€¢ When using autoregressive VLAs
  â€¢ Multi-robot generalization (use FAST+)

Diffusion:
  â€¢ When you have 5x more compute budget
  â€¢ When inference latency is not critical
  â€¢ Highly multimodal action distributions
"""

ax.text(
    0.02,
    0.98,
    comparison_text,
    fontsize=10,
    va="top",
    ha="left",
    family="monospace",
    bbox=dict(boxstyle="round", facecolor="lightyellow", alpha=0.95),
)

plt.tight_layout()
plt.savefig("results/tokenization_comparison.png", dpi=150, bbox_inches="tight")
print("âœ… Saved tokenization comparison to: results/tokenization_comparison.png")
plt.close()

print("\nğŸ“š Summary:")
print("   â€¢ FAST uses DCT (like JPEG) to compress robot actions")
print("   â€¢ FSQ quantization converts frequency coefficients to discrete tokens")
print("   â€¢ 15x compression: 120 action values â†’ 8 tokens")
print("   â€¢ Enables autoregressive VLAs for dexterous, high-frequency control")
print("   â€¢ 5x faster training than diffusion while matching performance")
print("\nğŸ“– Paper: https://arxiv.org/pdf/2501.09747")
